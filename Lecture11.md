 Sharon Shi (leader), Sarah Li (leader), Zhaofeng Li, Zhibin (Louis) Lu

##  Lecture 11 Exploration / Exploitation (2)

| Contents                                              | PPT      |
| ----------------------------------------------------- | -------- |
| Optimism Under Uncertainty for Bandits                | 8-17 9   |
| Bayesian Bandits and Bayesian Regret Framework        | 19-26 7  |
| Probability Matching                                  | 28-45 17 |
| Framework: Probably Approximately Correct for Bandits | 45-48 3  |
| MDPs                                                  | 49-61 12 |

**Note**: Out lecture 11 corresponds to the Lecture 12 in Youtube. https://www.youtube.com/watch?v=jJ7JbQBTChM&list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u&index=12

### March 21 - 26:

To Learn `Optimism Under Uncertainty for Bandits`. (We learn this part together, no task divided.)

We may need to learn the content in previous lecture that related to our lecture 11 (Recall: Multi-armed Bandit framework).



(61 - 8) /4 = 15

EST: 10pm - 11:59pm 

Video: 0:23min 

| Name  | Role                                                         |
| ----- | ------------------------------------------------------------ |
| Louis | Recall Lecure 11 + Optimism Under Uncertainty for Bandits `[UCB(upper confident bound) + Greedy Bandit Algorithms] `-17; 0:23min |
|       | Bayesian Bandits: Short Refresher + Framework: Regret and Bayesian Regret + Approach: Probability Matching  19-28;  <br />Thompson Sampling:    - 2 pages |
|       | Toy Example: Ways to Treat Broken Toes, Thompson Sampling.   |
| Sarah | MDPs                                                         |

